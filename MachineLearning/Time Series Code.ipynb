{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7pVCrK04YtZ"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Time series modeling is a set of tools and techniques that model temporal or time series data and aim to predict or forecast future behavior of the data. It has applications in various fields such as finance, economics, weather forecasting, and more.\n",
    "\n",
    "By analyzing historical data, we can identify different components in time series data such as trends, seasonality, and so on, and use these insights to make more informed business decisions.\n",
    "\n",
    "In this demonstration, we will explore a few different techniques for time series modeling. As we construct and evaluate our models, we'll gain insight into how different techniques can be used to handle common challenges in time series modeling.\n",
    "\n",
    "\n",
    "## Problem Statement\n",
    "In  this demonstration, we will apply time series modeling techniques to a real-world problem that involves a company and its sales. The company has historical sales data that it has captured over a period of time and wishes to forecast future sales trends so that it may optimize its inventory management processes.\n",
    "\n",
    "The problem statement for this demonstration can be summarized as follows:\n",
    "> Given historical sales data of a company, forecast its future sales.\n",
    "\n",
    "By studying the forecast, the company can effectively plan and prepare their inventory to ensure that the right amount of stock is made ready over future months.\n",
    "\n",
    "## Data Description\n",
    "You have been provided with a data set containing daily sales and profit data of the company for the period 2011 to 2014. The data set has the following three attributes:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th> Attributes </th>\n",
    "    <th> Description <th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td> Order-Date </td>\n",
    "    <td> The date on which the order was placed (in dd-mm-yyyy format) </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td> Sales </td>\n",
    "    <td> Total sales value of the transaction (in dollars) </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td> Profit </td>\n",
    "    <td> Profit made on the transaction (in dollars) </td>\n",
    "  </tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "## Outline\n",
    "In this demonstration, we will:\n",
    "- Prepare the data for time series modeling\n",
    "- Forecast sales using the following models:\n",
    "  - Autoregressive (AR)\n",
    "  - Autoregressive integrated moving average (ARIMA)\n",
    "  - Seasonal autoregressive integrated moving average (SARIMA)\n",
    "\n",
    "We will analyze the performance of these models using root mean squared error (RMSE) and mean absolute percentage error (MAPE).\n",
    "\n",
    "Please note that while we could evaluate the performance of the forecasting models using any one of RMSE or MAPE, to obtain a more comprehensive assessment of their performance, we will use both measures for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RipP3fNfjAd7"
   },
   "source": [
    "# Part 1 - Setup and Data Preparation\n",
    "In this section, we will:\n",
    "- Import necessary packages for executing the code\n",
    "- Load the data\n",
    "- Prepare the data for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGrL1GtX4Ytd"
   },
   "outputs": [],
   "source": [
    "# Import 'numpy' and 'pandas' for working with numbers and dataframes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import 'pyplot' from 'matplotlib' and 'seaborn' for visualizations\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import and execute method for suppressing warnings\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQfR6jia4Ytf"
   },
   "source": [
    "Let's begin by loading the data and building familiarity with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVIuDl4ePfmd"
   },
   "source": [
    "As you can see, the data type of the *Order Date* column is *object*. But to further conduct analyses on the data, such as grouping by month or year, we have to convert the data type of the *Order Date* column to *datetime*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHQoVrblj6cR"
   },
   "source": [
    "Let's make sure that the data points in the data frame are ordered by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgGLdnNBZMBy"
   },
   "source": [
    "Next, we will set the updated *Order Date* feature as the index of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwxB8iGKjAd8"
   },
   "source": [
    "To study monthly sales, we need to group the rows of *df* by month and sum up the values in each group. We will use the *Grouper* function in conjunction with the *groupby* operation for grouping. *Grouper* is a function in the *pandas* library that allow us to group time series data based on a specific frequency (*freq*) which in our case is monthly (*M*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLcg1P-fj6cT"
   },
   "source": [
    "You can see that only one date from each month is used in the index as representative of each of those months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "teJN-vIqjAd9"
   },
   "source": [
    "Recall from the problem statement that we are interested in forecasting *Sales*. So, we can drop the *Profit* feature from our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhVhtKVQRjKF"
   },
   "source": [
    "Let's now plot our data set to visualize our time series and try to identify patterns in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xj06B5hQj6cV"
   },
   "source": [
    "# Part 2 - Stationarity Analysis\n",
    "In this part of the demonstration, we will perform tests on the time series data to understand whether it is stationary or not. The autoregressive modeling requires the time series data to be stationary. To test this, we will use the following test:\n",
    "- Augmented Dickeyâ€“Fuller (ADF) test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7dWeMCej6cX"
   },
   "source": [
    "### ADF Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llOUzEa8j6cX"
   },
   "source": [
    "Note that the null hypothesis for the ADF test is *The time series is not stationary*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9kf0eENaj6cX",
    "outputId": "b8181168-bd03-4e3e-f892-64dc8aea4053"
   },
   "outputs": [],
   "source": [
    "# Use the ADF test to check for the stationarity of the 'Sales' variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYZbQKfxj6cY"
   },
   "source": [
    "If the $p$-value is < $0.05$, then our data is stationary otherwise our data is non-stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yr6OMfeHj6cY"
   },
   "source": [
    "We have analyzed our time series data. Let's now split the data into training and testing sets so that we're ready to build and evaluate time series models on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IT2-c370j6cu"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing data sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "leDFXudtj6cu",
    "outputId": "1d383032-92af-4430-e40d-83cc5bc5d3d9"
   },
   "outputs": [],
   "source": [
    "# Plot the time series data with the train-test split\n",
    "plt.figure(figsize = (14, 6))\n",
    "sns.lineplot(data = df_train, x = 'Order Date', y = 'Sales', marker = 'o', color = 'blue', label = 'Train')\n",
    "sns.lineplot(data = df_test, x = 'Order Date', y = 'Sales', marker = 'o', color = 'green', label = 'Test')\n",
    "plt.title('Sales Data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kcsg4vVJj6cv"
   },
   "source": [
    "# Part 3 - Time Series Transformations\n",
    "Now we will transform the time series data so that it ends up having a more stationary mean and variance. To do this, we will use the following data transformations:\n",
    "- Box-Cox transformation\n",
    "- Differencing\n",
    "\n",
    "Box-Cox transformation is used to make the variance of a time series stationary and differencing is used to make its mean stationary. Note that although these methods can be executed in any order, differencing is done after Box-Cox transformation in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fCP59kJj6cv"
   },
   "source": [
    "### Subpart 1 - Box-Cox Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHr7Bdehj6cv"
   },
   "source": [
    "The Box-Cox transformation is used to stabilize the variance of a time series. It involves the application of a power transformation to the time series data. Let's import the *boxcox* method from *scipy* to implement this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "az3-BT0bj6cv"
   },
   "outputs": [],
   "source": [
    "# Import the 'boxcox' method from 'scipy' to implement the Box-Cox transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i15QqMd8j6cv"
   },
   "source": [
    "Note that from here on out, we will only perform data transformations on the training data to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqDvyZ98j6cw"
   },
   "outputs": [],
   "source": [
    "# Use the 'boxcox' method to transform the 'Sales' variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "id": "r5UFpKY_j6cw",
    "outputId": "4260bc6b-b6fd-4f33-d0aa-42c57ccc47ef"
   },
   "outputs": [],
   "source": [
    "# Plot the original time series data and its Box-Cox transformed version\n",
    "plt.figure(figsize = (14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.lineplot(data = df_train, x = 'Order Date', y = 'Sales', marker = 'o', color = 'blue')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title('Original Data')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.lineplot(x = df_boxcox.index, y = df_boxcox.values, marker = 'o', color = 'blue')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title('Box-Cox Transformed Data [lambda = 0]')\n",
    "\n",
    "plt.suptitle('Sales Data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2gYpGajj6cx"
   },
   "source": [
    "### Subpart 2 - Differencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3gdVgkjj6cx"
   },
   "source": [
    "Differencing is used to stabilize the mean of a time series. It involves taking the difference of consecutive data points in the time series. If this process is executed once, it is known as first-order differencing. If done twice, it is called second-order differencing. And so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7kmRv2fj6cx"
   },
   "outputs": [],
   "source": [
    "# Obtain the first-order differenced version of the time series data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Uajf4hlj6cy"
   },
   "source": [
    "Note that differencing results in a missing value at the beginning of the series, but this is not of much consequence for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "id": "sEV56Xkej6cy",
    "outputId": "f1daadd2-e052-4476-e086-1c4121b8132b"
   },
   "outputs": [],
   "source": [
    "# Plot the original time series data and its first-order differenced version\n",
    "plt.figure(figsize = (14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.lineplot(data = df_train, x = 'Order Date', y = 'Sales', marker = 'o', color = 'blue')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title('Original Data')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.lineplot(x = df_differenced.index, y = df_differenced.values, marker = 'o', color = 'blue')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title('Differenced Data [Order = 1]')\n",
    "\n",
    "plt.suptitle('Sales Data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVLYjgfgj6cy"
   },
   "source": [
    "We will continue with difference order $=1$ for the remainder of the demonstration. However, you are free to analyze the impact of other order values on the mean of the time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6xtx0MHj6cz"
   },
   "source": [
    "### Subpart 3 - Transformed Time Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRuffzRaj6cz"
   },
   "source": [
    "We will now apply the Box-Cox and the differencing transformations on the training data so that the data is ready for autoregressive time series modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VhiDJsP1j6cz"
   },
   "outputs": [],
   "source": [
    "# Apply the Box-Cox and differencing transformations on the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "id": "oWuHQvoAj6c0",
    "outputId": "efb00839-8649-4b5b-997f-b1030a2c8fb4"
   },
   "outputs": [],
   "source": [
    "# Plot the original time series data and its transformed version\n",
    "plt.figure(figsize = (14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.lineplot(data = df_train, x = 'Order Date', y = 'Sales', marker = 'o', color = 'blue')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title('Original Data')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.lineplot(x = df_boxcox_diff.index, y = df_boxcox_diff.values, marker = 'o', color = 'blue')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title('Transformed Data [lambda = 0 and differencing order = 1]')\n",
    "\n",
    "plt.suptitle('Sales Data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GJcUQ0pj6c0"
   },
   "source": [
    "# Part 4 - Autocorrelation Plots\n",
    "In this part of the demonstration, we will compute and visualize the autocorrelation function (ACF) and the partial autocorrelation function (PACF) plots for the time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNTKJDMAj6c0"
   },
   "source": [
    "### Subpart 1 - Autocorrelation Function (ACF) Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ttow1-Tj6c0"
   },
   "source": [
    "The autocorrelation function (ACF) plot shows the autocorrelation values of a time series for different lag orders. Let's import the *plot_acf* method from *statsmodels* to implement this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-w6xU7kj6c1"
   },
   "outputs": [],
   "source": [
    "# Import 'plot_acf' from 'statsmodels' to compute and visualize the autocorrelation function (ACF) for the time series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "T0Gqase_j6c1",
    "outputId": "cdf16b94-01d3-4034-af9b-9a8c56c6578e"
   },
   "outputs": [],
   "source": [
    "# Note: Since differencing results in a missing value at the beginning, we must exclude it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Q548dlDj6c1"
   },
   "source": [
    "We can see a strong autocorrelation value at lag order $=1$. There is other lag order value where it is strong as well, such as $12$, but $1$ is the strongest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEacRJVdj6c1"
   },
   "source": [
    "### Subpart 2 - Partial Autocorrelation Function (PACF) Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQynzLGbj6c2"
   },
   "source": [
    "The partial autocorrelation fucntion (PACF) plot shows the partial autocorrelation values of a time series for different lag orders. Partial autocorrelation is computed such that it ignores short-term correlations in the data. Let's import the *plot_pacf* method from *statsmodels* to implement this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G4tRFxkQj6c2"
   },
   "outputs": [],
   "source": [
    "# Import 'plot_pacf' from 'statsmodels' to compute and visualize the partial autocorrelation function (ACF) for the time series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "wcBbSW-Tj6c2",
    "outputId": "159eb379-aa28-4d44-a6c6-84f2f3f1f112"
   },
   "outputs": [],
   "source": [
    "# Note: Since differencing results in a missing value at the beginning, we must exclude it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOqd2ICAtgj-"
   },
   "source": [
    "# Part 5 - Autoregressive Models\n",
    "In this part of the demonstration, we will fit autoregressive models to the data and anaylze their performance using RMSE and MAPE values. We will build the following models:\n",
    "- Autoregressive (AR)\n",
    "- Autoregressive integrated moving average (ARIMA)\n",
    "- Seasonal autoregressive integrated moving average (SARIMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHE2dz0Gj6c3"
   },
   "source": [
    "### Subpart 1 - Autoregressive (AR) Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QG2vlLj0j6c3"
   },
   "source": [
    "We will begin by fitting a basic autoregressive model to the training data and analyze its performance. We will use the *ARIMA* method from *statsmodels* to build the model.\n",
    "\n",
    "**Note:** The *ARIMA* method can also be used to implement other autoregressive models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8R2GCxKNj6c3"
   },
   "source": [
    "Let's import the *ARIMA* method from *statsmodels*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpSTZMojj6c3"
   },
   "outputs": [],
   "source": [
    "# Import 'ARIMA' from 'statsmodels' for building autoregressive models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J-Lsy8iTj6c4",
    "outputId": "ed4f45b3-e952-45a9-cee8-6386e736d5da"
   },
   "outputs": [],
   "source": [
    "# Fit an AR model to the transformed training data with lag order 1 and view its optimal parameter values\n",
    "# Note: You may try other suitable lag order values as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwYMGn1Fj6c4"
   },
   "outputs": [],
   "source": [
    "# Obtain predictions from the AR model for the testing data indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_4zZKevj6c5"
   },
   "outputs": [],
   "source": [
    "# Append the predictions with 'df_boxcox_diff' to prepare the data for inverse transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jnVyeQVRj6c5"
   },
   "outputs": [],
   "source": [
    "# Reverse the differencing transformation that was done on the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_y3P-JUFj6c5"
   },
   "outputs": [],
   "source": [
    "# Reverse the Box-Cox transformation that was done on the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iSRzdWQj6c5"
   },
   "source": [
    "Let's visualize the predictions along with the data before computing error measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "38WK7fclj6c-",
    "outputId": "3c95c271-1faa-4e11-e59e-9b3d318c70a2"
   },
   "outputs": [],
   "source": [
    "# Plot the time series data with the train-test split and the testing data predictions\n",
    "plt.figure(figsize = (14, 6))\n",
    "sns.lineplot(data = df_train, x = 'Order Date', y = 'Sales', marker = 'o', color = 'blue', label = 'Train')\n",
    "sns.lineplot(data = df_test, x = 'Order Date', y = 'Sales', marker = 'o', color = 'green', label = 'Test')\n",
    "sns.lineplot(x = df_preds.index[train_len:], y = df_preds.values[train_len:], marker = 'o', color = 'purple', label = 'Predictions')\n",
    "plt.title('Sales Data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uVQZ2u3j6c-"
   },
   "source": [
    "Next, let's compute performance metrics for the model. But to do that, we will first import the *mean_squared_error* function from *sklearn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eRzdeo4nj6c-"
   },
   "outputs": [],
   "source": [
    "# Import 'mean_squared_error' from 'sklearn' for error computations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "4SG5SX9Zj6c_",
    "outputId": "9a8e6dfc-af57-40c3-8cc1-89baecfa5c73"
   },
   "outputs": [],
   "source": [
    "# Summarize the performance of the model on the test data using RMSE and MAPE\n",
    "rmse = np.sqrt(mean_squared_error(y_true = df_test['Sales'], y_pred = df_preds.values[train_len:]))\n",
    "\n",
    "rmse = np.round(rmse, 2)\n",
    "\n",
    "performance_df = pd.DataFrame(index = [0],data = {'Model': 'AR', 'RMSE': rmse})\n",
    "\n",
    "performance_df.set_index('Model', inplace = True)\n",
    "\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KyiL2AEj6dF"
   },
   "source": [
    "### Autoregressive Integrated Moving Average (ARIMA) Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzaqVmJjj6dF"
   },
   "source": [
    "We will now a fit an autoregressive integrated moving average model to the training data and analyze its performance. We will use the *ARIMA* method from *statsmodels* to build the model.\n",
    "\n",
    "**Note:** The *ARIMA* method can also be used to implement other autoregressive models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAnkPl2nj6dF"
   },
   "source": [
    "The parameter of interest in the *ARIMA* method is the *order* parameter. It is a 3-tuple of the form $(p, d, q)$ with the default value as $(0, 0, 0)$.\n",
    "\n",
    "For the ARIMA method, we will specify all the values in this tuple. The first and the third values are the $p$ and $q$ values or the lag orders obtained from the PACF and the ACF plots respectively. The second value in the tuple is $d$ or the differencing order which we shall set as $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EOlw-mcVj6dF",
    "outputId": "06cf96b1-97ce-470a-efd3-cdf128fa8667"
   },
   "outputs": [],
   "source": [
    "# Fit an ARIMA model to the transformed training data with 'p = 11', 'd = 1' and 'q = 1' and view its optimal parameter values\n",
    "# Note: Since differencing is integrated into the ARIMA method, we will use 'df_boxcox' instead of 'df_boxcox_diff'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MyZPriX3j6dF"
   },
   "outputs": [],
   "source": [
    "# Obtain predictions from the ARIMA model for the testing data indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_BZcwqe8j6dG"
   },
   "outputs": [],
   "source": [
    "# Append the predictions with 'df_boxcox' to prepare the data for inverse transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dx2t7t0Wj6dG"
   },
   "outputs": [],
   "source": [
    "# Reverse the Box-Cox transformation that was done on the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4rw3EBSj6dG"
   },
   "source": [
    "Let's visualize the predictions along with the data before computing error measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "X8LWXPsmj6dG",
    "outputId": "93e27314-5fa4-487e-d784-798c6c6e84a6"
   },
   "outputs": [],
   "source": [
    "# Plot the time series data with the train-test split and the testing data predictions\n",
    "plt.figure(figsize = (14, 6))\n",
    "sns.lineplot(data = df_train, x = 'Order Date', y = 'Sales', marker = 'o', color = 'blue', label = 'Train')\n",
    "sns.lineplot(data = df_test, x = 'Order Date', y = 'Sales', marker = 'o', color = 'green', label = 'Test')\n",
    "sns.lineplot(x = df_preds.index[train_len:], y = df_preds.values[train_len:], marker = 'o', color = 'purple', label = 'Predictions')\n",
    "plt.title('Sales Data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qoScqr_j6dH"
   },
   "source": [
    "Next, let's compute performance metrics for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "vpUPx4JPj6dH",
    "outputId": "cfc84b20-dae5-47ec-c176-fa8476c312ff"
   },
   "outputs": [],
   "source": [
    "# Summarize the performance of the model on the test data using RMSE and MAPE\n",
    "rmse = np.sqrt(mean_squared_error(y_true = df_test['Sales'], y_pred = df_preds.values[train_len:]))\n",
    "\n",
    "rmse = np.round(rmse, 2)\n",
    "\n",
    "performance_df_temp = pd.DataFrame(index = [0], data = {'Model': 'ARIMA', 'RMSE': rmse})\n",
    "\n",
    "performance_df_temp.set_index('Model', inplace = True)\n",
    "\n",
    "performance_df = pd.concat([performance_df, performance_df_temp])\n",
    "\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8vebzCwj6dH"
   },
   "source": [
    "### Subpart 5 - Seasonal Autoregressive Integrated Moving Average (SARIMA) Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhdtzoFrj6dI"
   },
   "source": [
    "We will now a fit a seasonal autoregressive integrated moving average model to the training data and analyze its performance. We will use the *SARIMAX* method from *statsmodels* to build the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lV1qaqcLj6dI"
   },
   "source": [
    "Let's import the *SARIMAX* method from *statsmodels*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dtc4xbKsj6dI"
   },
   "outputs": [],
   "source": [
    "# Import 'SARIMAX' from 'statsmodels' for building autoregressive models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QsOjILCj6dI"
   },
   "source": [
    "The parameters of interest in the *SARIMAX* method are the *order* and the *seasonal_order* parameters. The *order* parameter is a 3-tuple of the form $(p, d, q)$ with the default value as $(0, 0, 0)$ and the *seasonal_order* parameter is a 4-tuple of the form $(P, D, Q, m)$ with the default value as $(0, 0, 0, 0)$.\n",
    "\n",
    "For the SARIMA method, we will specify all the values in the two tuples.\n",
    "\n",
    "The *seasonal_order* parameter specifies the lag and difference orders for the seasonal component of the model, along with its period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEWQkV1Yj6dJ",
    "outputId": "a2110d49-629f-4354-8dc4-77c143feea7b"
   },
   "outputs": [],
   "source": [
    "# Note: We know that the seasonality period in the data is 'm = 12'\n",
    "# Note: Since differencing is integrated into the SARIMA method, we will use 'df_boxcox' instead of 'df_boxcox_diff'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4klTK8uj6dJ"
   },
   "outputs": [],
   "source": [
    "# Obtain predictions from the SARIMA model for the testing data indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2RJTUyKCj6dJ"
   },
   "outputs": [],
   "source": [
    "# Append the predictions with 'df_boxcox' to prepare the data for inverse transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LIYa8UM9j6dJ"
   },
   "outputs": [],
   "source": [
    "# Reverse the Box-Cox transformation that was done on the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5TevvmBj6dK"
   },
   "source": [
    "Let's visualize the predictions along with the data before computing error measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "V_pl2m62j6dK",
    "outputId": "1b32c811-b3db-45f4-9a44-9e12e28e4584"
   },
   "outputs": [],
   "source": [
    "# Plot the time series data with the train-test split and the testing data predictions\n",
    "plt.figure(figsize = (14, 6))\n",
    "sns.lineplot(data = df_train, x = 'Order Date', y = 'Sales', marker = 'o', color = 'blue', label = 'Train')\n",
    "sns.lineplot(data = df_test, x = 'Order Date', y = 'Sales', marker = 'o', color = 'green', label = 'Test')\n",
    "sns.lineplot(x = df_preds.index[train_len:], y = df_preds.values[train_len:], marker = 'o', color = 'purple', label = 'Predictions')\n",
    "plt.title('Sales Data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2U2Y6clj6dK"
   },
   "source": [
    "Next, let's compute performance metrics for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "3DiRAaVtj6dK",
    "outputId": "b9b97861-96f1-40cd-8d9e-89ee09b43f37"
   },
   "outputs": [],
   "source": [
    "# Summarize the performance of the model on the test data using RMSE and MAPE\n",
    "rmse = np.sqrt(mean_squared_error(y_true = df_test['Sales'], y_pred = df_preds.values[train_len:]))\n",
    "\n",
    "rmse = np.round(rmse, 2)\n",
    "\n",
    "performance_df_temp = pd.DataFrame(index = [0], data = {'Model': 'SARIMA', 'RMSE': rmse})\n",
    "\n",
    "performance_df_temp.set_index('Model', inplace = True)\n",
    "\n",
    "performance_df = pd.concat([performance_df, performance_df_temp])\n",
    "\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
